---
title: "Homework 5"
author: Yaa Ababio
output: github_document
---


```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

#### Read in and describe the raw data
```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv")
```
The Washington Post dataset contains information about `r nrow(homicide_df)` homicides that occurred in 50 large US cities between the years 2007 and 2017. This dataset contains `r ncol(homicide_df)` variables that describe the date of the homicide, location of the homicide, characteristics of the victim, and status of the case related to the homicide. These variables are as follows: `r names(homicide_df)`.


#### Create `city_state` variable and `resolved` variable

```{r}
homicide_df = 
homicide_df %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


#### Summarize within cities to obtain total number of homicides and unsolved homicides. 

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )

```


#### Use `prop.test` function to estimate proportion of unsolved homicides, save output as an R object, and pull the estimated proportion and confidence intervals from tidy dataframe using `broom::tidy`.

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```


#### Run `prop.test` for each of the cities, and extract both the proportion of unsolved homicides and the confidence interval for each. 

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```


#### Create a plot that shows the estimates and CIs for reach city.
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```





## Problem 2 

#### Create a dataframe that contains all file names using the `list.files`  and `purrr::map` functions.

```{r}
path_df = 
  tibble(
    path = list.files("lda_data"),
  ) %>% 
  mutate(
    path = str_c("lda_data/", path),
    data = map(path, read_csv)) %>%
  unnest(data)
    
   
```

#### Tidy the dataframe. 
```{r}
long_study_df = 
path_df %>%
  separate(path, into = c(NA, "arm_ID"), sep = "/") %>%
  separate(arm_ID, into = c("arm", "ID.csv"), sep = "_") %>%
  separate(ID.csv, into = c("subject_id", NA)) %>%
  mutate(
    arm = recode(arm,
               con = "control",
               exp = "experimental")
    ) %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observations"
  )
```


#### Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups. 

```{r}
long_study_df %>%
  group_by(arm, subject_id) %>%
  ggplot(aes(x = week, y = observations, group = subject_id, color = arm)) +
  geom_path() 
```


```{r}
long_study_df %>%
ggplot(aes(week, observations, group = subject_id, color = subject_id)) +
  geom_line() +
  facet_grid(~arm) 
```




## Problem 3


